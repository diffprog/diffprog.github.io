<!DOCTYPE HTML PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>The Elements of Differentiable Programming book</title>
  <link rel="stylesheet" href="style.css" type="text/css" media="screen">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sugina-dev/latin-modern-web@1.0.1/style/latinmodern-sans.css" />
</head>

<body>
  <h1>The Elements of Differentiable Programming</h1>

  <h2>Book</h2>

  <p>Book draft available on <a href="https://arxiv.org/abs/2403.14606">arXiv</a>.</p>

  <h3>Abstract</h3>

  <p>Artificial intelligence has recently experienced remarkable advances,
  fueled by large models, vast datasets, accelerated hardware, and, last but
  not least, the transformative power of differentiable programming. This new
  programming paradigm enables end-to-end differentiation of complex computer
  programs (including those with control flows and data structures), making
  gradient-based optimization of program parameters possible.
  As an emerging paradigm, differentiable programming builds upon several areas
  of computer science and applied mathematics, including automatic
  differentiation, graphical models, optimization and statistics. This book
  presents a comprehensive review of the fundamental concepts useful for
  differentiable programming. We adopt two main perspectives, that of
  optimization and that of probability, with clear analogies between the two.
  Differentiable programming
  is not merely the differentiation of programs, but also the thoughtful design
  of programs intended for differentiation. By making programs differentiable,
  we inherently introduce probability distributions over their execution,
  providing a means to quantify the uncertainty associated with program
  outputs.</p>
  
  <h3>Table of contents</h3>

  <ul>
    <li>1. Introduction</li>
    <li>I. Fundamentals</li>
      <ul>
        <li>2. Differentiation</li>
        <li>3. Probabilistic learning</li>
      </ul>
    <li>II. Differentiable programs</li>
      <ul>
        <li>4. Parameterized programs</li>
        <li>5. Control flows</li>
      </ul>
    <li>III. Differentiating through programs</li>
      <ul>
        <li>6. Finite differences</li>
        <li>7. Automatic differentiation</li>
        <li>8. Second-order automatic differentiation</li>
        <li>9. Inference in graphical models as differentiation</li>
        <li>10. Differentiating through optimization</li>
        <li>11. Differentiating through integration</li>
      </ul>
    <li>IV. Smoothing programs</li>
      <ul>
        <li>12. Smoothing by optimization</li>
        <li>13. Smoothing by integration</li>
      </ul>
    <li>V. Optimizing differentiable programs</li>
      <ul>
        <li>14. Optimization basics</li>
        <li>15. First-order optimization</li>
        <li>16. Second-order optimization</li>
        <li>17. Duality</li>
      </ul>
  </ul>

  <h3>How to cite</h3>

  <span>
    @article{edpbook, <br/ >
    title={The {E}lements of {D}ifferentiable {P}rogramming}, <br/ >
    author={Blondel, Mathieu and Roulet, Vincent}, <br/ >
    journal={arXiv preprint arXiv:2403.14606}, <br/ >
    year={2024} <br/ >
}
  </span>

  <h2>Code</h2>

  <p>Python code accompanying the book is available in this 
  <a href="https://github.com/diffprog/code">github repository</a>.</p>

  <h2>Authors</h2>

  <ul>
    <li><a href="https://mblondel.org">Mathieu Blondel</a>, Google DeepMind, mblondel@google.com</li>
    <li><a href="https://vroulet.github.io">Vincent Roulet</a>, Google DeepMind, vroulet@google.com</li>
  </ul>

  <p>Feel free to email us with suggestions, mistakes, typos. We are grateful for any feedback!</p> 

</body>
</html>
